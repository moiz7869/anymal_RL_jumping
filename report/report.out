\BOOKMARK [1][-]{section.1}{Reinforcement learning algorithm}{}% 1
\BOOKMARK [1][-]{section.2}{Hyper-parameters effects on the performance}{}% 2
\BOOKMARK [1][-]{section.3}{Observations and their updates}{}% 3
\BOOKMARK [1][-]{section.4}{Curriculumn learning}{}% 4
\BOOKMARK [1][-]{section.5}{Training}{}% 5
\BOOKMARK [2][-]{subsection.5.1}{Introduction}{section.5}% 6
\BOOKMARK [2][-]{subsection.5.2}{Related quantities for reward functions}{section.5}% 7
\BOOKMARK [3][-]{subsubsection.5.2.1}{2D position error}{subsection.5.2}% 8
\BOOKMARK [3][-]{subsubsection.5.2.2}{2D body velocity}{subsection.5.2}% 9
\BOOKMARK [3][-]{subsubsection.5.2.3}{Relative angle of velocity vector and position error vector}{subsection.5.2}% 10
\BOOKMARK [3][-]{subsubsection.5.2.4}{Reward coefficient}{subsection.5.2}% 11
\BOOKMARK [2][-]{subsection.5.3}{Penalties}{section.5}% 12
\BOOKMARK [3][-]{subsubsection.5.3.1}{Torque penalty}{subsection.5.3}% 13
\BOOKMARK [3][-]{subsubsection.5.3.2}{Joint velocity penalty}{subsection.5.3}% 14
\BOOKMARK [2][-]{subsection.5.4}{Rewards}{section.5}% 15
\BOOKMARK [3][-]{subsubsection.5.4.1}{Moving toward the goal reward}{subsection.5.4}% 16
\BOOKMARK [3][-]{subsubsection.5.4.2}{Near the goal reward}{subsection.5.4}% 17
\BOOKMARK [2][-]{subsection.5.5}{Terminal States}{section.5}% 18
\BOOKMARK [3][-]{subsubsection.5.5.1}{Too far from the goal}{subsection.5.5}% 19
\BOOKMARK [3][-]{subsubsection.5.5.2}{Reaching the goal}{subsection.5.5}% 20
\BOOKMARK [3][-]{subsubsection.5.5.3}{Violation of joint velocity constraints}{subsection.5.5}% 21
\BOOKMARK [1][-]{section.6}{Result}{}% 22
\BOOKMARK [1][-]{section.7}{Future works}{}% 23
\BOOKMARK [1][-]{section.8}{Acknowledgement and feedback}{}% 24
